# Backend: optional overrides (defaults in core/config.py)
# AI_TC_GEN_DEFAULT_LLM_PROVIDER=ollama
# AI_TC_GEN_OLLAMA_BASE_URL=http://localhost:11434
# AI_TC_GEN_OLLAMA_MODEL=llama3.2:3b

# OpenAI (required when using GPT-4o Mini or GPT-4o)
# AI_TC_GEN_OPENAI_API_KEY=your-openai-api-key

# Gemini (required when using Gemini 2.5 Flash)
# AI_TC_GEN_GEMINI_API_KEY=your-gemini-api-key

# Groq (required when using Llama 3.3 70B)
# AI_TC_GEN_GROQ_API_KEY=your-groq-api-key
